{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Modelo B\n",
    "\n",
    "Basado en PCA y clusters:\n",
    "- PCA\n",
    "- Clusterización en 3 grupos\n",
    "- Gridsearch de LGBM para cada grupo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamiento de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualización\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Modelos\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score, precision_score, recall_score, \\\n",
    "roc_curve, roc_auc_score, ConfusionMatrixDisplay, multilabel_confusion_matrix\n",
    "\n",
    "# Otros\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'..\\data\\processed\\train_2.csv').drop(columns='id')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamiento\n",
    "Lo mismo que en notebook 2 pero sin log ni escalado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OHE\n",
    "ohe = OneHotEncoder(sparse=False, handle_unknown='ignore', dtype=int)\n",
    "\n",
    "encoded_mtrans = pd.DataFrame(ohe.fit_transform(df[['mtrans']]),\n",
    "                             columns=ohe.get_feature_names_out(['mtrans']),\n",
    "                             index=df.index)\n",
    "\n",
    "# Elimino una de las columnas para mejorar el rendimiento\n",
    "encoded_mtrans.drop(columns='mtrans_physic', inplace=True)\n",
    "\n",
    "# Concateno\n",
    "df = pd.concat([df, encoded_mtrans], axis=1).drop(columns='mtrans')\n",
    "\n",
    "\n",
    "\n",
    "# MAPEO\n",
    "df.caec = df.caec.map({'no':0,\n",
    "                     'Sometimes':1,\n",
    "                     'Frequently':2,\n",
    "                     'Always':3})\n",
    "df.calc = df.calc.map({'no':0,\n",
    "                     'Sometimes':1,\n",
    "                     'Frequently':2})\n",
    "df.nobeyesdad = df.nobeyesdad.map({'Insufficient_Weight':0,\n",
    "           'Normal_Weight':1,\n",
    "           'Overweight_Level_I':2,\n",
    "           'Overweight_Level_II':3,\n",
    "           'Obesity_Type_I':4,\n",
    "           'Obesity_Type_II':5,\n",
    "           'Obesity_Type_III':6})\n",
    "\n",
    "\n",
    "# SELECCIÓN COLUMNAS\n",
    "df = df[['age', 'height', 'weight', 'family_history_with_overweight', 'favc', 'fcvc', 'caec', 'ch2o', 'faf', 'nobeyesdad']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separo la target\n",
    "X = df.drop(columns='nobeyesdad')\n",
    "y = df['nobeyesdad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "print('Varianza explicada por cada dimensión:', pca.explained_variance_ratio_)\n",
    "print('Varianza explicada total:', pca.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "Vamos a clusterizar en 3 grupos. Idealmente, la división sería:\n",
    "- C1: insufficient weight y normal weight\n",
    "- C2: overweight_I, overweight_II\n",
    "- C3: obesity_type_I, obesity_type_II, obesity_type_III\n",
    "\n",
    "Evidentemente, no podemos asegurar que el algoritmo vaya a realizar esta división. Se adjunta esta información sólo para justificar el porqué de los 3 grupos."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
