{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Modelo C\n",
    "Basado en el conocimiento del \"negocio\".\\\n",
    "Según las fuentes consultadas, el sobrepeso se calcula en base al IMC, el cual a su vez se calcula diviendo el peso en kg entre el cuadrado de la altura en metros.\n",
    "\n",
    "<center>\n",
    "\n",
    "$IMC = kg/m^2$ \n",
    "\n",
    "\n",
    "\n",
    "| IMC        \t| Diagnóstico       \t|\n",
    "|------------\t|-------------------\t|\n",
    "| <18.5      \t| Peso insuficiente \t|\n",
    "| (18.5, 25) \t| Peso normal       \t|\n",
    "| (25, 30)   \t| Sobrepeso         \t|\n",
    "| >30        \t| Obesidad          \t|\n",
    "\n",
    "</center>\n",
    "\n",
    "\\\n",
    "El principal factor adicional que interviene en esta categorización es si el sujeto es deportista o no, y más concretamente si se dedica a la alterofilia. Un sujeto con estas características puede dar positivo en sobrepeso pero no tener nada de masa grasa, debido a su masa muscular. Por desgracia, el dataset ofrece este último dato de manera poco exhaustiva: la FAF sólo tiene valores enteros del 0 al 2. \\\n",
    "\\\n",
    "Procedimiento:\n",
    "- Crear un modelo con las variables peso y altura\n",
    "- Crear un segundo modelo añadiendo la variable faf\n",
    "- Comparar los modelos entre sí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamiento de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Modelos\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, BaggingClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score, precision_score, recall_score, \\\n",
    "roc_curve, roc_auc_score, ConfusionMatrixDisplay, multilabel_confusion_matrix\n",
    "\n",
    "# Otros\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'..\\data\\processed\\train_3.csv')\n",
    "df_1 = df[['height', 'weight', 'nobeyesdad']]\n",
    "df_2 = df[['height', 'weight', 'faf', 'nobeyesdad']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## División de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(df_1.drop(columns=['nobeyesdad']),\n",
    "                                                    df_1['nobeyesdad'],\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=df_1['nobeyesdad'])\n",
    "\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(df_2.drop(columns=['nobeyesdad']),\n",
    "                                                    df_2['nobeyesdad'],\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=df_2['nobeyesdad'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos = {LogisticRegression(random_state=42):'LogR',\n",
    "           SVC(kernel='linear', random_state=42): 'SVC_linear',\n",
    "           SVC(kernel='poly', degree=4): 'SVC_poly',\n",
    "           SVC(random_state=42):'SVC_rbf',\n",
    "           DecisionTreeClassifier(random_state=42):'DT',\n",
    "           RandomForestClassifier(random_state=42, class_weight='balanced'):'RF',\n",
    "           KNeighborsClassifier(n_neighbors=5):'KNEIGH',\n",
    "           lgb.LGBMClassifier():'LGBM',\n",
    "           XGBClassifier():'XGB'}\n",
    "\n",
    "scores = ['accuracy']\n",
    "data_1 = []\n",
    "data_2 = []\n",
    "\n",
    "for modelo in modelos:\n",
    "    print(f'processing {modelo}')\n",
    "    data_1.append([(cross_val_score(modelo, X_train_1, y_train_1, cv=5, scoring=score)).mean() for score in scores])\n",
    "    data_2.append([(cross_val_score(modelo, X_train_2, y_train_2, cv=5, scoring=score)).mean() for score in scores])\n",
    "\n",
    "baselines = pd.DataFrame([data_1, data_2], columns=['accuracy', 'accuracy (faf)'], index=modelos.values())\n",
    "baselines.sort_values(by='accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento y validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELO_ELEGIDO.fit()\n",
    "accuracy_score(y_test, MODELO_ELEGIDO.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "filename = 'my_model_3.sav'\n",
    "joblib.dump(MODELO_ELEGIDO, filename)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
